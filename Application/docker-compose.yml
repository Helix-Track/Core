version: '3.8'

services:
  # HelixTrack Core with SQLite
  helixtrack-core:
    build:
      context: .
      dockerfile: Dockerfile.parametrized
      args:
        BUILD_VERSION: ${BUILD_VERSION:-1.0.0}
        BUILD_DATE: ${BUILD_DATE:-$(date -u +"%Y-%m-%dT%H:%M:%SZ")}
        BUILD_COMMIT: ${BUILD_COMMIT:-dev}
    container_name: helixtrack-core-sqlite
    hostname: helixtrack-core
    restart: unless-stopped

    # Environment variables from .env.sqlite
    env_file:
      - .env.sqlite

    # Additional environment overrides
    environment:
      - DB_TYPE=sqlite
      - DB_PATH=/app/Database/helixtrack.db
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8080

    # Ports
    ports:
      - "${SERVER_PORT:-8080}:8080"
      - "${METRICS_PORT:-9090}:9090"

    # Volumes
    volumes:
      - ./Database:/app/Database
      - ./logs:/app/logs
      - ./Configurations:/app/Configurations:ro

    # Health check
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # Networks
    networks:
      - helixtrack-network

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

  # Mock Authentication Service (for testing)
  mock-auth-service:
    image: alpine:latest
    container_name: mock-auth-service
    command: >
      sh -c "
        apk add --no-cache python3 py3-pip &&
        pip3 install flask &&
        python3 -c '
from flask import Flask, jsonify, request
app = Flask(__name__)

@app.route(\"/health\", methods=[\"GET\"])
def health():
    return jsonify({\"status\": \"healthy\"}), 200

@app.route(\"/authenticate\", methods=[\"POST\"])
def authenticate():
    data = request.get_json()
    if data.get(\"username\") and data.get(\"password\"):
        return jsonify({
            \"token\": \"mock-jwt-token\",
            \"claims\": {
                \"sub\": \"authentication\",
                \"name\": data.get(\"username\"),
                \"username\": data.get(\"username\"),
                \"role\": \"admin\"
            }
        }), 200
    return jsonify({\"error\": \"Invalid credentials\"}), 401

@app.route(\"/validate\", methods=[\"GET\"])
def validate():
    auth_header = request.headers.get(\"Authorization\")
    if auth_header and \"Bearer\" in auth_header:
        return jsonify({
            \"username\": \"testuser\",
            \"name\": \"Test User\",
            \"role\": \"user\"
        }), 200
    return jsonify({\"error\": \"Unauthorized\"}), 401

if __name__ == \"__main__\":
    app.run(host=\"0.0.0.0\", port=8081)
        '
      "
    ports:
      - "8081:8081"
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s

  # Mock Permissions Service (for testing)
  mock-perm-service:
    image: alpine:latest
    container_name: mock-perm-service
    command: >
      sh -c "
        apk add --no-cache python3 py3-pip &&
        pip3 install flask &&
        python3 -c '
from flask import Flask, jsonify, request
app = Flask(__name__)

@app.route(\"/health\", methods=[\"GET\"])
def health():
    return jsonify({\"status\": \"healthy\"}), 200

@app.route(\"/check\", methods=[\"POST\"])
def check():
    data = request.get_json()
    username = data.get(\"username\", \"\")
    # Simple mock: admins have all permissions
    allowed = username == \"admin\" or data.get(\"required_level\", 5) <= 1
    return jsonify({
        \"allowed\": allowed,
        \"reason\": \"Mock permission check\"
    }), 200

@app.route(\"/permissions/<username>\", methods=[\"GET\"])
def permissions(username):
    return jsonify({
        \"permissions\": [
            {\"context\": \"org/team1\", \"level\": 1},
            {\"context\": \"org/team2\", \"level\": 3}
        ]
    }), 200

if __name__ == \"__main__\":
    app.run(host=\"0.0.0.0\", port=8082)
        '
      "
    ports:
      - "8082:8082"
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8082/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s

  # Prometheus (optional - for monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: helixtrack-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9091:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - helixtrack-network
    restart: unless-stopped
    profiles:
      - monitoring

  # Grafana (optional - for visualization)
  grafana:
    image: grafana/grafana:latest
    container_name: helixtrack-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - helixtrack-network
    restart: unless-stopped
    profiles:
      - monitoring

  # PostgreSQL database for Chat service
  chat-db:
    image: postgres:15-alpine
    container_name: helixtrack-chat-db
    hostname: chat-db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=helixtrack_chat
      - POSTGRES_USER=chat_user
      - POSTGRES_PASSWORD=${CHAT_DB_PASSWORD:-chat_secure_password_change_me}
      - POSTGRES_INITDB_ARGS=--encoding=UTF8 --lc-collate=C --lc-ctype=C
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - chat-db-data:/var/lib/postgresql/data
      - ../Services/Chat/../../Database/DDL/Extensions/Chats/Definition.V2.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    ports:
      - "5433:5432"
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U chat_user -d helixtrack_chat"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # PostgreSQL database for Localization service
  localization-db:
    image: postgres:15-alpine
    container_name: helixtrack-localization-db
    hostname: localization-db
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${LOCALIZATION_DB_NAME:-helixtrack_localization}
      - POSTGRES_USER=${LOCALIZATION_DB_USER:-localization_user}
      - POSTGRES_PASSWORD=${LOCALIZATION_DB_PASSWORD:-localization_secure_password_change_me}
      - POSTGRES_INITDB_ARGS=--encoding=UTF8 --lc-collate=C --lc-ctype=C
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - localization-db-data:/var/lib/postgresql/data
      - ../../Database/DDL/Services/Localization/Definition.V1.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
      - ../../Database/DDL/Services/Localization/Migration.V1.2.sql:/docker-entrypoint-initdb.d/02-migration.sql:ro
    ports:
      - "${LOCALIZATION_DB_PORT:-5434}:5432"
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${LOCALIZATION_DB_USER:-localization_user} -d ${LOCALIZATION_DB_NAME:-helixtrack_localization}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Localization microservice
  localization-service:
    build:
      context: ../Services/Localization
      dockerfile: Dockerfile
    container_name: helixtrack-localization-service
    hostname: localization-service
    restart: unless-stopped
    depends_on:
      localization-db:
        condition: service_healthy
    environment:
      - DB_HOST=localization-db
      - DB_PORT=5432
      - DB_NAME=${LOCALIZATION_DB_NAME:-helixtrack_localization}
      - DB_USER=${LOCALIZATION_DB_USER:-localization_user}
      - DB_PASSWORD=${LOCALIZATION_DB_PASSWORD:-localization_secure_password_change_me}
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-key-change-in-production}
      - SEED_DATA_PATH=seed-data
      - LOG_LEVEL=info
    ports:
      - "${LOCALIZATION_PORT:-8085}:8085"
    volumes:
      - ../Services/Localization/configs:/app/configs:ro
      - ../Services/Localization/certs:/app/certs:ro
      - ../Services/Localization/backups:/app/backups
      - localization-logs:/app/logs
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD", "curl", "--insecure", "--fail", "https://localhost:8085/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Chat microservice
  chat-service:
    build:
      context: ../Services/Chat
      dockerfile: Dockerfile
    container_name: helixtrack-chat-service
    hostname: chat-service
    restart: unless-stopped
    depends_on:
      chat-db:
        condition: service_healthy
    environment:
      - DB_PASSWORD=${CHAT_DB_PASSWORD:-chat_secure_password_change_me}
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-key-change-in-production}
    ports:
      - "9090:9090"
    volumes:
      - ../Services/Chat/configs/prod.json:/app/configs/prod.json:ro
      - ../Services/Chat/certs:/app/certs:ro
      - chat-logs:/var/log/helixtrack/chat
    networks:
      - helixtrack-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

networks:
  helixtrack-network:
    driver: bridge
    name: helixtrack-network

volumes:
  prometheus-data:
    name: helixtrack-prometheus-data
  grafana-data:
    name: helixtrack-grafana-data
  chat-db-data:
    name: helixtrack-chat-db-data
  chat-logs:
    name: helixtrack-chat-logs
  localization-db-data:
    name: helixtrack-localization-db-data
  localization-logs:
    name: helixtrack-localization-logs
